{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### **if you liked my notebook give a upvote and help me to get my first ever bronze üôè**\n",
    "feel free to put up questions in comment box \n",
    "* follow me on youtube for tutorial videos @https://www.youtube.com/c/AbhishekJaiswal24"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### About Dataset\n",
    "* The dataset consists of training data, validation data, and testing data.\n",
    "* The training data consists of 5,216 chest x-ray images with 3,875 images shown to have pneumonia and 1,341 images shown to be normal.\n",
    "* The validation data is relatively small with only 16 images with 8 cases of pneumonia and 8 normal cases.\n",
    "* The testing data consists of 624 images split between 390 pneumonia cases and 234 normal cases.\n",
    "\n",
    "\n",
    "#### What is Pneumonia?\n",
    "<img src = 'https://i.ibb.co/tqCHdDV/pneumonia.png'>\n",
    "* Pneumonia is an infection in one or both lungs. Bacteria, viruses, and fungi cause it. The infection causes inflammation in the air sacs in your lungs, which are called alveoli. The alveoli fill with fluid or pus, making it difficult to breathe.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### here we will classify pneumonia vs normal looking xray using CNN and pretrained model \n",
    "<img src = 'https://i.ibb.co/Sw52m0T/model.png'>\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Before Further do i wanna share some result of my reasearch on this project to save your time and efforts\n",
    "<img src = 'https://i.ibb.co/c2NtHN6/evaluation-1.png'  width = 800 height = 70>\n",
    "<img src = 'https://i.ibb.co/6w2d343/evaluation2.png' width = 800 height = 70>\n",
    "this result will help us to choose models and building stacked model "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### i will be using pretrained mobilenet, densenet169 and stacked model of (mobilenet and densenet169)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### After looking these result lets build our own model for greater accuracy"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### STEP-1 (importing libraries)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# making all imports \n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T07:33:35.624486Z",
     "iopub.execute_input": "2021-05-26T07:33:35.624796Z",
     "iopub.status.idle": "2021-05-26T07:33:35.635679Z",
     "shell.execute_reply.started": "2021-05-26T07:33:35.624767Z",
     "shell.execute_reply": "2021-05-26T07:33:35.634523Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### STEP-2 (creating the path )"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "main_dir = \"./data/chest_xray/\"\n",
    "train_data_dir = main_dir + \"train/\"\n",
    "validation_data_dir = main_dir + \"val/\"\n",
    "test_data_dir = main_dir + \"test/\"\n",
    "\n",
    "\n",
    "print(\"Working Directory Contents:\", os.listdir(main_dir))\n",
    "\n",
    "# creating path is really important when we deal with multiple folder and files "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T07:05:42.937493Z",
     "iopub.execute_input": "2021-05-26T07:05:42.937981Z",
     "iopub.status.idle": "2021-05-26T07:05:42.951158Z",
     "shell.execute_reply.started": "2021-05-26T07:05:42.937938Z",
     "shell.execute_reply": "2021-05-26T07:05:42.950297Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_n = train_data_dir+'NORMAL/'\ntrain_p = train_data_dir+'PNEUMONIA/'\n\nprint(\"length of cases in training set:\",len(os.listdir(train_p)) + len(os.listdir(train_n)))\nprint(\"length of pneumonia cases in training set:\",len(os.listdir(train_p)))\nprint(\"length of normal cases in training set:\",len(os.listdir(train_n)))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T07:05:44.377958Z",
     "iopub.execute_input": "2021-05-26T07:05:44.378322Z",
     "iopub.status.idle": "2021-05-26T07:05:44.587462Z",
     "shell.execute_reply.started": "2021-05-26T07:05:44.378293Z",
     "shell.execute_reply": "2021-05-26T07:05:44.58652Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Some image processing can help us to understand the xray \n\nfor image processing we create a function and put in lambda layer in our model , \n\nfor Xray-classification i have found out the CLAHE and image normalization helps up to get better result",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Quick look to the images \nclahe = cv2.createCLAHE(clipLimit = 5)\n\n\nimg_name = 'IM-0115-0001.jpeg'\nimg_normal = cv2.imread('../input/chest-xray-pneumonia/chest_xray/train/NORMAL/' + img_name)\nimg_normal = cv2.resize(img_normal, (500,500))\nimg_normal = cv2.cvtColor(img_normal, cv2.COLOR_BGR2GRAY)\nimg_normal_clahe = clahe.apply(img_normal) + 30\n\n\n\nimg_name_1 = 'person1000_virus_1681.jpeg'\nimg_pneumonia = cv2.imread('../input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA/' + img_name_1)\nimg_pneumonia = cv2.resize(img_pneumonia, (500,500))\nimg_pneumonia = cv2.cvtColor(img_pneumonia, cv2.COLOR_BGR2GRAY)\nimg_pneumonia_clahe = clahe.apply(img_pneumonia) + 30\n\n\n#-----------------------------------------------------------------------------------------#\n\n\nfig, axs = plt.subplots(2,2,figsize=(10,6))\naxs[0,0].imshow(img_normal)\naxs[0,0].set_title(\"NORMAL\")\naxs[0,1].imshow(img_normal_clahe)\naxs[0,1].set_title(\"NORMAL_CLAHE\")\naxs[1,0].imshow(img_pneumonia)\naxs[1,0].set_title(\"PNEUMONIA\")\naxs[1,1].imshow(img_pneumonia_clahe)\naxs[1,1].set_title(\"PNEUMNIA_CLAHE\");\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T07:07:27.01234Z",
     "iopub.execute_input": "2021-05-26T07:07:27.012668Z",
     "iopub.status.idle": "2021-05-26T07:07:27.631132Z",
     "shell.execute_reply.started": "2021-05-26T07:07:27.012641Z",
     "shell.execute_reply": "2021-05-26T07:07:27.62622Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### STEP-3( Creating the generator for fitting to the model)\nwe need generator because training big amount of images can take us to memory insufficient error\n\nhere generator will do all our image processing task for training ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "### here we will apply image augumentation only on the training images not on testing or validation \nimg_width , img_height = [224,224]\nbatch_size = 16\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    brightness_range=[0.2,1.0],\n    horizontal_flip=True)\n\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\nval_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_width, img_height),\n    batch_size=batch_size,\n    class_mode='binary',\n    shuffle = True)\n\nvalidation_generator = val_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary')\n\ntest_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T07:07:50.188259Z",
     "iopub.execute_input": "2021-05-26T07:07:50.188572Z",
     "iopub.status.idle": "2021-05-26T07:07:52.981322Z",
     "shell.execute_reply.started": "2021-05-26T07:07:50.188542Z",
     "shell.execute_reply": "2021-05-26T07:07:52.98057Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "##### here we can draw some batch to see how our image looks like after data augmentation\nits a good practice to see our data after augumentation ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\nimage_batch, label_batch = next(iter(train_generator))\n\ndef show_batch(image_batch, label_batch):\n    plt.figure(figsize=(10, 10))\n    for n in range(15):\n        ax = plt.subplot(5, 5, n + 1)\n        plt.imshow(image_batch[n])\n        if label_batch[n]:\n            plt.title(\"PNEUMONIA\")\n        else:\n            plt.title(\"NORMAL\")\n        plt.axis(\"off\")\n\nshow_batch(image_batch, label_batch)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T07:08:29.338576Z",
     "iopub.execute_input": "2021-05-26T07:08:29.338906Z",
     "iopub.status.idle": "2021-05-26T07:08:30.733145Z",
     "shell.execute_reply.started": "2021-05-26T07:08:29.338869Z",
     "shell.execute_reply": "2021-05-26T07:08:30.732367Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "nb_train_samples = 5216 # number of training samples\nnb_validation_samples = 16 # number of validation samples\nnb_test_samples = 624 # number of training samples\nepochs = 20  # number of epochs we gonna run\nbatch_size  = 16 # batch size ( at every iteration it will take 16 batches for training)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T07:09:34.344521Z",
     "iopub.execute_input": "2021-05-26T07:09:34.344864Z",
     "iopub.status.idle": "2021-05-26T07:09:34.348775Z",
     "shell.execute_reply.started": "2021-05-26T07:09:34.344811Z",
     "shell.execute_reply": "2021-05-26T07:09:34.347753Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### STEP-4 (Defining the model) \n\n#### Here we are going to use Pretrained models for better accuracy since our Custom CNN didn't give good results",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### 1- DenseNet169 ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from tensorflow.keras.applications.densenet import DenseNet169\nfrom tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n\nbase = DenseNet169(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\ntf.keras.backend.clear_session()\n\nfor layer in base.layers:\n    layer.trainable =  False # freezing densenet layers \n\ndensenet_model = Sequential()\ndensenet_model.add(base)\ndensenet_model.add(GlobalAveragePooling2D())\ndensenet_model.add(BatchNormalization())\ndensenet_model.add(Dense(256, activation='relu'))\ndensenet_model.add(Dropout(0.5))\ndensenet_model.add(BatchNormalization())\ndensenet_model.add(Dense(128, activation='relu'))\ndensenet_model.add(Dropout(0.5))\ndensenet_model.add(Dense(1, activation='sigmoid'))\n\ndensenet_model.summary()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T08:18:47.802682Z",
     "iopub.execute_input": "2021-05-26T08:18:47.803074Z",
     "iopub.status.idle": "2021-05-26T08:18:52.139151Z",
     "shell.execute_reply.started": "2021-05-26T08:18:47.803042Z",
     "shell.execute_reply": "2021-05-26T08:18:52.138376Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# defined optimizer\noptm = Adam(lr=0.0001)\ndensenet_model.compile(loss='binary_crossentropy', optimizer=optm, \n                  metrics=['accuracy'])\n\n# defining callbacks \n\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\nEarlyStopping = EarlyStopping(monitor='val_accuracy',\n                              min_delta=.01,\n                              patience=7,\n                              verbose=1,\n                              mode='max',\n                              baseline=None,\n                              restore_best_weights=True)\n\nrlr = ReduceLROnPlateau( monitor=\"val_accuracy\",\n                            factor=0.01,\n                            patience=3,\n                            verbose=0,\n                            mode=\"max\",\n                            min_delta=0.01)\n\nmodel_save = ModelCheckpoint('./densenet169.h5',\n                             save_best_only = True,\n                             save_weights_only = False,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\n\n\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T08:19:11.923398Z",
     "iopub.execute_input": "2021-05-26T08:19:11.923726Z",
     "iopub.status.idle": "2021-05-26T08:19:11.946777Z",
     "shell.execute_reply.started": "2021-05-26T08:19:11.923697Z",
     "shell.execute_reply": "2021-05-26T08:19:11.945868Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "### Training our model\ndense_history = densenet_model.fit(train_generator,\n                              steps_per_epoch = nb_train_samples // batch_size,\n                              epochs = 20,\n                              validation_data = test_generator,\n                           \n                              callbacks=[EarlyStopping, model_save,rlr])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T08:19:12.962402Z",
     "iopub.execute_input": "2021-05-26T08:19:12.962691Z",
     "iopub.status.idle": "2021-05-26T08:38:56.249374Z",
     "shell.execute_reply.started": "2021-05-26T08:19:12.962664Z",
     "shell.execute_reply": "2021-05-26T08:38:56.248437Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# its always a good practice to load the model after saving with the best epochs \ndensenet_model = keras.models.load_model('./densenet169.h5')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T08:40:04.674722Z",
     "iopub.execute_input": "2021-05-26T08:40:04.675065Z",
     "iopub.status.idle": "2021-05-26T08:40:09.595585Z",
     "shell.execute_reply.started": "2021-05-26T08:40:04.675037Z",
     "shell.execute_reply": "2021-05-26T08:40:09.594775Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Defining some function for plotting and Testing",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### defining a function for plotting history object",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# for plotting learning curve \ndef plot(history):\n\n    training_accuracy = history.history['accuracy']\n    validation_accuracy = history.history['val_accuracy']\n\n    training_loss = history.history['loss']\n    validation_loss = history.history['val_loss']\n\n    epochs_range=range(len(training_accuracy))\n\n    plt.figure(figsize=(8, 8))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, training_accuracy, label='Training Accuracy')\n    plt.plot(epochs_range, validation_accuracy, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, training_loss, label='Training Loss')\n    plt.plot(epochs_range, validation_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T08:40:09.597006Z",
     "iopub.execute_input": "2021-05-26T08:40:09.597309Z",
     "iopub.status.idle": "2021-05-26T08:40:09.604472Z",
     "shell.execute_reply.started": "2021-05-26T08:40:09.597274Z",
     "shell.execute_reply": "2021-05-26T08:40:09.603569Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### for testing purpose we created a function\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nfrom PIL import Image\ndef predict(image_path, model):\n    im = cv2.imread(image_path)\n    test_image = np.asarray(im)\n    processed_test_image = process_image(test_image)\n    processed_test_image = np.expand_dims(processed_test_image, axis = 0)\n    \n    ps = model.predict(processed_test_image)\n    return ps\n    \ndef process_image(image):\n    image = image/255\n    image = cv2.resize(image, (224,224))\n    return image\n\n\ndef testing(model, test_df):\n    \"\"\" the passed data must be the img_path columns and label column\"\"\"\n    base_pred =[]\n    for image in test_df.img_path:\n        base_pred.append(predict(image , model)[0][0])\n    \n    final_base_pred  = np.where(np.array(base_pred)>0.5,1,0)\n    actual_label = test_df['label']\n    # print(final_base_pred)\n\n    print(classification_report(actual_label, final_base_pred))\n    matrix=confusion_matrix(actual_label, final_base_pred)\n    sns.heatmap(matrix,square=True, annot=True, fmt='d', cbar=False,\n            xticklabels=['0', '1'],\n            yticklabels=['0', '1'])\n    plt.xlabel('Predicted label')\n    plt.ylabel('True label')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T08:40:10.044234Z",
     "iopub.execute_input": "2021-05-26T08:40:10.044486Z",
     "iopub.status.idle": "2021-05-26T08:40:10.052527Z",
     "shell.execute_reply.started": "2021-05-26T08:40:10.044462Z",
     "shell.execute_reply": "2021-05-26T08:40:10.051744Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "##### The function we have created for testing takes a dataframe ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# for evaluation point of view i have created a dataframe of test directory \ntest_data = []\ntest_normal_path = test_data_dir + '/NORMAL'\ntest_pneumonia_path = test_data_dir + '/PNEUMONIA'\nfor filename in os.listdir(test_normal_path):\n    test_data.append((os.path.join(test_normal_path,filename),0))\nfor filename in os.listdir(test_pneumonia_path):\n    test_data.append((os.path.join(test_pneumonia_path,filename),1))    \n    \n    \n    \n    \ntest_df = pd.DataFrame(test_data, columns = ['img_path','label'], index = None)\n# this test_df must contain the img_path and label column in order to run the function    ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T08:40:12.97933Z",
     "iopub.execute_input": "2021-05-26T08:40:12.979649Z",
     "iopub.status.idle": "2021-05-26T08:40:12.994527Z",
     "shell.execute_reply.started": "2021-05-26T08:40:12.979621Z",
     "shell.execute_reply": "2021-05-26T08:40:12.993592Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "\nplot(dense_history)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T08:40:13.058729Z",
     "iopub.execute_input": "2021-05-26T08:40:13.058995Z",
     "iopub.status.idle": "2021-05-26T08:40:13.324029Z",
     "shell.execute_reply.started": "2021-05-26T08:40:13.058971Z",
     "shell.execute_reply": "2021-05-26T08:40:13.323285Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "densenet_model = keras.models.load_model('./densenet169.h5')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "testing(densenet_model, test_df)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T08:40:18.879229Z",
     "iopub.execute_input": "2021-05-26T08:40:18.87954Z",
     "iopub.status.idle": "2021-05-26T08:41:08.81198Z",
     "shell.execute_reply.started": "2021-05-26T08:40:18.879511Z",
     "shell.execute_reply": "2021-05-26T08:41:08.811163Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## MobilenetV2",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-23T20:08:20.938371Z",
     "iopub.execute_input": "2021-05-23T20:08:20.93872Z",
     "iopub.status.idle": "2021-05-23T20:08:20.942379Z",
     "shell.execute_reply.started": "2021-05-23T20:08:20.938683Z",
     "shell.execute_reply": "2021-05-23T20:08:20.941452Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n\nbase = MobileNetV2(weights = 'imagenet', include_top = False, input_shape= (224, 224, 3))\ntf.keras.backend.clear_session()\n    \nfor layer in base.layers:\n    layer.trainable =  False\n\nmobilenet_model = Sequential()\nmobilenet_model.add(base)\nmobilenet_model.add(GlobalAveragePooling2D())\nmobilenet_model.add(BatchNormalization())\nmobilenet_model.add(Dense(256, activation='relu'))\nmobilenet_model.add(Dropout(0.5))\nmobilenet_model.add(BatchNormalization())\nmobilenet_model.add(Dense(128, activation='relu'))\nmobilenet_model.add(Dropout(0.5))\nmobilenet_model.add(Dense(1, activation='sigmoid'))\n\nmobilenet_model.summary()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:16:36.423035Z",
     "iopub.execute_input": "2021-05-26T09:16:36.423357Z",
     "iopub.status.idle": "2021-05-26T09:16:37.739489Z",
     "shell.execute_reply.started": "2021-05-26T09:16:36.423327Z",
     "shell.execute_reply": "2021-05-26T09:16:37.738688Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# defined optimizer\noptm = Adam(lr=0.0001)\nmobilenet_model.compile(loss='binary_crossentropy', optimizer=optm, \n                  metrics=['accuracy'])\n\n# defining callbacks \n\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\nEarlyStopping = EarlyStopping(monitor='val_accuracy',\n                              min_delta=.001,\n                              patience=6,\n                              verbose=1,\n                              mode='auto',\n                              baseline=None,\n                              restore_best_weights=True)\n\nrlr = ReduceLROnPlateau( monitor=\"val_accuracy\",\n                            factor=0.01,\n                            patience=4,\n                            verbose=0,\n                            mode=\"max\",\n                            min_delta=0.01)\n\nmodel_save = ModelCheckpoint('./mobilenet.h5',\n                             save_best_only = True,\n                             save_weights_only = False,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\n\n\n### Training our model\nmobilenet_history = mobilenet_model.fit(train_generator,\n                              steps_per_epoch = nb_train_samples // batch_size,\n                              epochs = 20,\n                              validation_data = test_generator,\n                           \n                              callbacks=[EarlyStopping, model_save,rlr])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T08:41:22.485024Z",
     "iopub.execute_input": "2021-05-26T08:41:22.485335Z",
     "iopub.status.idle": "2021-05-26T08:58:31.156109Z",
     "shell.execute_reply.started": "2021-05-26T08:41:22.485306Z",
     "shell.execute_reply": "2021-05-26T08:58:31.155182Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "plot(mobilenet_history)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:16:16.552311Z",
     "iopub.execute_input": "2021-05-26T09:16:16.552621Z",
     "iopub.status.idle": "2021-05-26T09:16:16.802589Z",
     "shell.execute_reply.started": "2021-05-26T09:16:16.552591Z",
     "shell.execute_reply": "2021-05-26T09:16:16.801658Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "mobilenet_model = keras.models.load_model('./mobilenet.h5')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:18:29.732361Z",
     "iopub.execute_input": "2021-05-26T09:18:29.732679Z",
     "iopub.status.idle": "2021-05-26T09:18:31.065702Z",
     "shell.execute_reply.started": "2021-05-26T09:18:29.73265Z",
     "shell.execute_reply": "2021-05-26T09:18:31.064898Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "testing(mobilenet_model, test_df)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:18:31.971737Z",
     "iopub.execute_input": "2021-05-26T09:18:31.972077Z",
     "iopub.status.idle": "2021-05-26T09:19:09.95652Z",
     "shell.execute_reply.started": "2021-05-26T09:18:31.972048Z",
     "shell.execute_reply": "2021-05-26T09:19:09.955746Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Stacked Model (MobilenetV2, Densenet169)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-23T20:27:29.248263Z",
     "iopub.execute_input": "2021-05-23T20:27:29.248579Z",
     "iopub.status.idle": "2021-05-23T20:27:29.253925Z",
     "shell.execute_reply.started": "2021-05-23T20:27:29.248549Z",
     "shell.execute_reply": "2021-05-23T20:27:29.253067Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": "from keras.layers.merge import concatenate\nfrom keras.layers import Input\nimport tensorflow as tf\n\ninput_shape = (224,224,3)\ninput_layer = Input(shape = (224, 224, 3))\n\n#first model\nbase_mobilenet = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = input_shape)\nbase_densenet = DenseNet169(weights = 'imagenet', include_top = False, input_shape = input_shape)\n\nfor layer in base_mobilenet.layers:\n    layer.trainable =  False\nfor layer in base_densenet.layers:\n    layer.trainable = False\n    \nmodel_mobilenet = base_mobilenet(input_layer)\nmodel_mobilenet = GlobalAveragePooling2D()(model_mobilenet)\noutput_mobilenet = Flatten()(model_mobilenet)\n\nmodel_densenet = base_densenet(input_layer)\nmodel_densenet = GlobalAveragePooling2D()(model_densenet)\noutput_densenet = Flatten()(model_densenet)\n\nmerged = tf.keras.layers.Concatenate()([output_mobilenet, output_densenet]) \n\nx = BatchNormalization()(merged)\nx = Dense(256,activation = 'relu')(x)\nx = Dropout(0.5)(x)\nx = BatchNormalization()(x)\nx = Dense(128,activation = 'relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(1, activation = 'sigmoid')(x)\nstacked_model = tf.keras.models.Model(inputs = input_layer, outputs = x)\n\n\n\n\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:19:42.543713Z",
     "iopub.execute_input": "2021-05-26T09:19:42.544071Z",
     "iopub.status.idle": "2021-05-26T09:19:48.820355Z",
     "shell.execute_reply.started": "2021-05-26T09:19:42.544042Z",
     "shell.execute_reply": "2021-05-26T09:19:48.819523Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "stacked_model.summary()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:19:48.821795Z",
     "iopub.execute_input": "2021-05-26T09:19:48.822126Z",
     "iopub.status.idle": "2021-05-26T09:19:48.871273Z",
     "shell.execute_reply.started": "2021-05-26T09:19:48.822093Z",
     "shell.execute_reply": "2021-05-26T09:19:48.870522Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# defined optimizer\noptm = Adam(lr=0.0001)\nstacked_model.compile(loss='binary_crossentropy', optimizer=optm, \n                  metrics=['accuracy'])\n\n# defining callbacks \n\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau\nEarlyStopping = EarlyStopping(monitor='val_accuracy',\n                              min_delta=.01,\n                              patience=6,\n                              verbose=1,\n                              mode='auto',\n                              baseline=None,\n                              restore_best_weights=True)\n\nrlr = ReduceLROnPlateau( monitor=\"val_accuracy\",\n                            factor=0.01,\n                            patience=6,\n                            verbose=0,\n                            mode=\"max\",\n                            min_delta=0.01)\n\nmodel_save = ModelCheckpoint('./stacked_model.h5',\n                             save_best_only = True,\n                             save_weights_only = False,\n                             monitor = 'val_loss', \n                             mode = 'min', verbose = 1)\n\n\n### Training our model\nstacked_history = stacked_model.fit(train_generator,\n                              steps_per_epoch = nb_train_samples // batch_size,\n                              epochs = 20,\n                              validation_data = test_generator,\n                           \n                              callbacks=[EarlyStopping, model_save,rlr])",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:20:08.083574Z",
     "iopub.execute_input": "2021-05-26T09:20:08.084027Z",
     "iopub.status.idle": "2021-05-26T09:47:33.150397Z",
     "shell.execute_reply.started": "2021-05-26T09:20:08.083979Z",
     "shell.execute_reply": "2021-05-26T09:47:33.149533Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "as we can see that the maximum val_accuracy is 94% and loss is .18 the minimum loss \n* we can further stack more model and can try to improve val_accuracy and val_loss",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "stacked_model = keras.models.load_model('./stacked_model.h5')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:49:40.567529Z",
     "iopub.execute_input": "2021-05-26T09:49:40.567878Z",
     "iopub.status.idle": "2021-05-26T09:49:46.457214Z",
     "shell.execute_reply.started": "2021-05-26T09:49:40.567847Z",
     "shell.execute_reply": "2021-05-26T09:49:46.456362Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "testing(stacked_model,test_df)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:54:10.167483Z",
     "iopub.execute_input": "2021-05-26T09:54:10.16781Z",
     "iopub.status.idle": "2021-05-26T09:55:00.904768Z",
     "shell.execute_reply.started": "2021-05-26T09:54:10.167772Z",
     "shell.execute_reply": "2021-05-26T09:55:00.904016Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Lets test our validation _df ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "#### Lets do some prediction on our validation data \n# for evaluation point of view i have created a dataframe of test directory \nvalidation_data = []\nvalidation_normal_path = validation_data_dir + '/NORMAL'\nvalidation_pneumonia_path = validation_data_dir + '/PNEUMONIA'\nfor filename in os.listdir(validation_normal_path):\n    validation_data.append((os.path.join(validation_normal_path,filename),0))\nfor filename in os.listdir(validation_pneumonia_path):\n    validation_data.append((os.path.join(validation_pneumonia_path,filename),1))    ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:55:08.721693Z",
     "iopub.execute_input": "2021-05-26T09:55:08.722042Z",
     "iopub.status.idle": "2021-05-26T09:55:08.730971Z",
     "shell.execute_reply.started": "2021-05-26T09:55:08.722012Z",
     "shell.execute_reply": "2021-05-26T09:55:08.730153Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "validation_df = pd.DataFrame(validation_data, columns = ['img_path','label'], index = None)\nvalidation_df = validation_df.sample(frac=1).reset_index(drop=True)\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:55:09.44122Z",
     "iopub.execute_input": "2021-05-26T09:55:09.441528Z",
     "iopub.status.idle": "2021-05-26T09:55:09.449231Z",
     "shell.execute_reply.started": "2021-05-26T09:55:09.4415Z",
     "shell.execute_reply": "2021-05-26T09:55:09.448355Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "validation_df.head()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:55:10.015739Z",
     "iopub.execute_input": "2021-05-26T09:55:10.016101Z",
     "iopub.status.idle": "2021-05-26T09:55:10.024862Z",
     "shell.execute_reply.started": "2021-05-26T09:55:10.016071Z",
     "shell.execute_reply": "2021-05-26T09:55:10.023929Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Testing all models on validation data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "testing(stacked_model, validation_df)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:55:11.852318Z",
     "iopub.execute_input": "2021-05-26T09:55:11.852627Z",
     "iopub.status.idle": "2021-05-26T09:55:13.327541Z",
     "shell.execute_reply.started": "2021-05-26T09:55:11.852597Z",
     "shell.execute_reply": "2021-05-26T09:55:13.326791Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "testing(mobilenet_model, validation_df)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:55:13.936391Z",
     "iopub.execute_input": "2021-05-26T09:55:13.936726Z",
     "iopub.status.idle": "2021-05-26T09:55:15.076722Z",
     "shell.execute_reply.started": "2021-05-26T09:55:13.936694Z",
     "shell.execute_reply": "2021-05-26T09:55:15.075868Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "testing(densenet_model, validation_df)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:55:15.08073Z",
     "iopub.execute_input": "2021-05-26T09:55:15.082725Z",
     "iopub.status.idle": "2021-05-26T09:55:16.518468Z",
     "shell.execute_reply.started": "2021-05-26T09:55:15.082686Z",
     "shell.execute_reply": "2021-05-26T09:55:16.517699Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### **as we can see that our stacked model classified all 16 chestx-ray correctly**",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### Takeaway:\n* as we can see that our stacked model has the lowest loss in 20 epochs and highest validation accuracy \n* further for model improvement we can apply preprocessing (CLAHE and normalization) for better model\n* we can stack more model and can try to improve our model",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "#### Testing on our DATA",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def predict_image(validation_df, model):\n    plt.figure(figsize=(6,6))\n    for index , data in validation_df[:10].iterrows():\n        img_name = data['img_path']\n        label = data['label']\n    \n        label_predicted = np.where((predict(img_name , model)[0][0])>0.5,'pneumonia','normal')\n        plt.imshow(load_img(img_name, target_size = (120,120)))\n        if label == 1:\n            plt.xlabel(f\"True:Pneumonia, Predicted:{label_predicted}\", fontsize = 15)\n        if label == 0:\n            plt.xlabel(f\"True:Normal, Predicted:{label_predicted}\", fontsize = 15)\n            \n        plt.tight_layout()\n        plt.show()\n    ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:57:46.438132Z",
     "iopub.execute_input": "2021-05-26T09:57:46.438449Z",
     "iopub.status.idle": "2021-05-26T09:57:46.444541Z",
     "shell.execute_reply.started": "2021-05-26T09:57:46.438421Z",
     "shell.execute_reply": "2021-05-26T09:57:46.443749Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "predict_image(validation_df, stacked_model)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-05-26T09:57:46.793073Z",
     "iopub.execute_input": "2021-05-26T09:57:46.793329Z",
     "iopub.status.idle": "2021-05-26T09:57:49.678099Z",
     "shell.execute_reply.started": "2021-05-26T09:57:46.793305Z",
     "shell.execute_reply": "2021-05-26T09:57:49.677233Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}